{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryannewyork/BlockFed/blob/master/FL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Libraries and Packages"
      ],
      "metadata": {
        "id": "6YH5e8QHUeW_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n68mJ4_lgL5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a36219-a081-4101-c75e-2d1e62a75a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install kora -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kora import drive\n",
        "drive.link_nbs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rjzc-NDL0QJ",
        "outputId": "c281e8d2-c263-4412-c35c-9c0b3856d9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flutils import *"
      ],
      "metadata": {
        "id": "RALkl7s3L6BZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cd7be1-8671-4f01-8833-1a9d82a3ccab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from /nbs/flutils.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers.legacy import SGD\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "vnUlMle3RoJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Processing Dataset"
      ],
      "metadata": {
        "id": "Lo74IltCUqP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/Datasets/swarm_aligned'"
      ],
      "metadata": {
        "id": "XTFAyXKzRr05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply our function\n",
        "data_list, label_list = load(data_path)\n",
        "labels = list(set(label_list.tolist())) #unique labels\n",
        "\n",
        "#binarize the labels\n",
        "#lb = LabelBinarizer()\n",
        "#label_list = lb.fit_transform(label_list)\n",
        "n_values = np.max(label_list) + 1\n",
        "label_list = np.eye(n_values)[label_list]"
      ],
      "metadata": {
        "id": "azIUV5RaUT3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_list, \n",
        "                                                    label_list, \n",
        "                                                    test_size=0.1, \n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "kW_Hi6s8UbuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Clients to Participate in FL"
      ],
      "metadata": {
        "id": "9mJ1P3WYUxwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create clients\n",
        "clients = create_clients(X_train, y_train, num_clients=10, initial='client')"
      ],
      "metadata": {
        "id": "Tb8aUxdxWilZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#process and batch the training data for each client\n",
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data)\n",
        "    \n",
        "#process and batch the test set  \n",
        "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
        "\n",
        "comms_round = 10 #number of global epochs\n",
        "    "
      ],
      "metadata": {
        "id": "Lj-GiP2MWmd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Optimizer (To Perform Gradient Descent)"
      ],
      "metadata": {
        "id": "eoZnxKF0VB1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create optimizer\n",
        "lr = 0.01 \n",
        "loss='categorical_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "optimizer = SGD(lr=lr, \n",
        "                decay=lr / comms_round, \n",
        "                momentum=0.9\n",
        "               ) \n",
        "\n",
        "#initialize global model\n",
        "#print(data_list.shape,labels)\n",
        "smlp_global = SimpleMLP()\n",
        "global_model = smlp_global.build(data_list.shape[1],len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prqEXphiWspZ",
        "outputId": "14aedbc2-f668-47e9-8dc9-295363d7a72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Averaging"
      ],
      "metadata": {
        "id": "Eylff1q5Vjla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#commence global training loop\n",
        "for comm_round in range(comms_round):\n",
        "            \n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "    \n",
        "    #initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    #randomize client data - using keys\n",
        "    client_names= list(clients_batched.keys())\n",
        "    random.shuffle(client_names)\n",
        "    \n",
        "    #loop through each client and create new local model\n",
        "    for client in tqdm(client_names , desc = 'Progress Bar'):\n",
        "        #time.sleep(0.5)\n",
        "        smlp_local = SimpleMLP()\n",
        "        local_model = smlp_local.build(data_list.shape[1],len(labels))\n",
        "        local_model.compile(loss=loss, \n",
        "                      optimizer=optimizer, \n",
        "                      metrics=metrics)\n",
        "        \n",
        "        #print(local_model.summary())\n",
        "        #print(clients_batched)\n",
        "        #set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "        \n",
        "        #fit local model with client's data\n",
        "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
        "        \n",
        "        #scale the model weights and add to list\n",
        "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "        \n",
        "        #clear session to free memory after each communication round\n",
        "        K.clear_session()\n",
        "        \n",
        "    lobal_acc: 69.734%\n",
        "    \n",
        "    #update global model \n",
        "    global_model.set_weights(average_weights)\n",
        "\n",
        "    #test global model and print out metrics after each communications round\n",
        "    for(X_test, Y_test) in test_batched:\n",
        "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZRLmUmKWx75",
        "outputId": "7bdc479c-541f-427d-e49d-64c3dcb01847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 10/10 [00:20<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 1s 5ms/step\n",
            "comm_round: 0 | global_acc: 69.734% | global_loss: 0.6601933240890503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 10/10 [00:16<00:00,  1.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 6ms/step\n",
            "comm_round: 1 | global_acc: 69.734% | global_loss: 0.6595581769943237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 6ms/step\n",
            "comm_round: 2 | global_acc: 69.734% | global_loss: 0.6602720618247986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 10/10 [00:19<00:00,  1.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 1s 8ms/step\n",
            "comm_round: 3 | global_acc: 69.734% | global_loss: 0.6593183875083923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 10/10 [00:18<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 5ms/step\n",
            "comm_round: 4 | global_acc: 69.734% | global_loss: 0.6596729755401611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 10/10 [00:18<00:00,  1.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 1s 9ms/step\n",
            "comm_round: 5 | global_acc: 69.734% | global_loss: 0.6601543426513672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 10/10 [00:18<00:00,  1.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 5ms/step\n",
            "comm_round: 6 | global_acc: 69.734% | global_loss: 0.6596036553382874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 10/10 [00:19<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 0s 5ms/step\n",
            "comm_round: 7 | global_acc: 69.734% | global_loss: 0.6597053408622742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress Bar: 100%|██████████| 10/10 [00:17<00:00,  1.79s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(320)\n",
        "smlp_SGD = SimpleMLP()\n",
        "SGD_model = smlp_SGD.build(data_list.shape[1], len(labels)) \n",
        "\n",
        "SGD_model.compile(loss=loss, \n",
        "              optimizer=optimizer, \n",
        "              metrics=metrics)"
      ],
      "metadata": {
        "id": "rHnS8zl8XZaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the SGD training data to model\n",
        "_ = SGD_model.fit(SGD_dataset, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "7H8k95bpXaS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the SGD global model and print out metrics\n",
        "for(X_test, Y_test) in test_batched:\n",
        "        SGD_acc, SGD_loss = test_model(X_test, Y_test, SGD_model, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWMN63yIXd63",
        "outputId": "b28ac2f1-01ed-4c7a-f21f-40a43ac6a334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 1s 7ms/step\n",
            "comm_round: 1 | global_acc: 69.734% | global_loss: 0.6598128080368042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGaNzTmgXPx2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}